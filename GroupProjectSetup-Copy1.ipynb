{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7654b128",
   "metadata": {},
   "source": [
    "### Installing dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76f402",
   "metadata": {},
   "source": [
    "                                                    Project details                                                                \n",
    "                                 \n",
    "The data represents various brain activities: resting, math & story tasks, working memory, and motor tasks.\n",
    "\n",
    "    The 'Intra' folder contains data from one subject, while the 'Cross' folder includes multiple subjects.\n",
    "\n",
    "Each file is a matrix of shape 248 x 35624, where 248 represents the number of sensors, and 35624 represents time steps.\n",
    "\n",
    "The files have the following format: “taskType subjectIdentifier number.h5”\n",
    "where taskType can be rest, task motor, task story math, and task working memory.\n",
    "\n",
    "In practice, these tasks correspond to the activities performed by the subjects:\n",
    "\n",
    "    • Resting Task\n",
    "Recording the subjects’ brain while in a relaxed resting\n",
    "state.\n",
    "\n",
    "    • Math & Story Task\n",
    "Subject performs mental calculation and language\n",
    "processing task.\n",
    "\n",
    "    • Working Memory task\n",
    "Subject performs a memorization task.\n",
    "\n",
    "    • Motor Task\n",
    "Subject performs a motor task, typically moving fingers\n",
    "or feets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a095d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import FloatTensor, LongTensor\n",
    "from typing import Tuple, List, Callable, Optional\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4a67a",
   "metadata": {},
   "source": [
    "Reading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447432ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(file_name_with_dir):\n",
    "    filename_without_dir = file_name_with_dir.split('/')[-1]\n",
    "    temp = filename_without_dir.split('_')[:-1]\n",
    "    dataset_name = \"_\".join(temp)\n",
    "    return dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cefcec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# min-max scaling\n",
    "def minmax(trial):\n",
    "    min = trial.min()\n",
    "    max = trial.max()\n",
    "    normalisedTrial = (trial - min)/(max-min)\n",
    "    return normalisedTrial\n",
    "\n",
    "#Z-score normalisation OPTIONAL\n",
    "def zscore(trial):\n",
    "    mean = trial.mean()\n",
    "    sd = trial.std()\n",
    "    normalisedTrial = (trial - mean)/sd \n",
    "    return normalisedTrial\n",
    "\n",
    "#downsamples data by totaltimesteps/factor\n",
    "def downsample(trial, factor):\n",
    "    ds_trial = trial[:,::factor]\n",
    "    return ds_trial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "520ca917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through RNN\n",
    "        rnn, _ = self.rnn(x)\n",
    "        \n",
    "        # Only take the output from the final time step\n",
    "        output = self.fc(rnn[:, -1, :])\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75a55a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for storing data in a folder into an array\n",
    "\n",
    "\n",
    "def preprocess_files(files = None, path = 'Final Project data/Cross/train', downsampling = 30):\n",
    "    label_to_int = {'rest': 0, 'task_motor': 1, 'task_story_math': 2, 'task_working_memory': 3}\n",
    "\n",
    "    cross_data_train = [] # Store data\n",
    "    cross_data_train_labels = [] # Store labels (based on filename)\n",
    "\n",
    "    if files == None:\n",
    "        files = os.listdir(path)\n",
    "\n",
    "    for file in files:\n",
    "        file_path = f'{path}/{file}'\n",
    "        \n",
    "        with h5py.File(file_path, 'r') as h5_file:\n",
    "            # obtain labels\n",
    "            dataset_name = get_dataset_name(file_path)\n",
    "            label = dataset_name.split('1')[0].removesuffix('_')\n",
    "            cross_data_train_labels.append(label_to_int[label])\n",
    "            \n",
    "            # obtain X_data\n",
    "            matrix = h5_file.get(dataset_name)[()]\n",
    "            normalisedMatrix = downsample(zscore(matrix), downsampling) # apply minmax normalisation and downsampling\n",
    "            cross_data_train.append(normalisedMatrix.T) # Transpose\n",
    "             \n",
    "    X = torch.from_numpy(np.array(cross_data_train)).float()\n",
    "    y = torch.tensor(cross_data_train_labels)        \n",
    "            \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94b27d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:03,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:07,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:10,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:14,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:18,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:21,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:25,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:28,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "input_size = 248\n",
    "hidden_size = 200\n",
    "output_size = 4\n",
    "network = RNN(input_size, hidden_size, output_size)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "path = 'Final Project data/Cross/train'\n",
    "files = os.listdir(path)\n",
    "current_samples = []\n",
    "n = 8\n",
    "batch_index = 1\n",
    "\n",
    "for i, file in tqdm(enumerate(files)):\n",
    "    current_samples.append(file)\n",
    "    if len(current_samples) == n or i == (len(files)-1):\n",
    "        print(f\"training batch {batch_index}...\")\n",
    "        X_train, y_train = preprocess_files(current_samples, downsampling=8) \n",
    "        current_samples = []\n",
    "        \n",
    "        network.train()\n",
    "        opt.zero_grad()\n",
    "        output = network(X_train)\n",
    "        loss = loss_fn(output, y_train)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        batch_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10e3fe33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing:\n",
    "path = 'Final Project data/Cross/test1'\n",
    "files = os.listdir(path)\n",
    "X, y = preprocess_files(files, path, 8)\n",
    "network.eval()\n",
    "\n",
    "test_output = network(X).detach().numpy()\n",
    "pred = np.argmax(test_output, axis=1) # to numpy\n",
    "y = y.numpy()\n",
    "\n",
    "accuracy_score(pred, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b4ac940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7a9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
